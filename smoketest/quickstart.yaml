# Service account for the agent
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: honeycomb-serviceaccount
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: honeycomb-serviceaccount
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: honeycomb-serviceaccount
subjects:
- kind: ServiceAccount
  name: honeycomb-serviceaccount
  namespace: default
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: honeycomb-serviceaccount
  namespace: default
rules:
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - list
    - watch

# ConfigMap specifying which logs the agent should watch
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: honeycomb-agent-config
  namespace: default
data:
  config.yaml: |-
    # By default, submit logs from interesting system pods such as the
    # kube API server, scheduler, etc
    watchers:
      - dataset: kubernetes-logs
        labelSelector: "component=kube-apiserver,tier=control-plane"
        namespace: kube-system
        parser: glog
      - dataset: kubernetes-logs
        labelSelector: "component=kube-scheduler,tier=control-plane"
        namespace: kube-system
        parser: glog
      - dataset: kubernetes-logs
        labelSelector: "component=kube-controller-manager,tier=control-plane"
        namespace: kube-system
        parser: glog
      - dataset: kubernetes-logs
        labelSelector: "k8s-app=kube-proxy"
        namespace: kube-system
        parser: glog
      - dataset: kubernetes-logs
        labelSelector: "k8s-app=kube-dns"
        namespace: kube-system
        parser: glog
      - dataset: frontend
        labelSelector: "app=guestbook"
        namespace: default
        parser: nop
    verbosity: debug
    # splitLogging directs trace, debug, info, and warn log levels to stdout
    # rather than stderr.
    splitLogging: false

# Daemonset
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    app: honeycomb-agent
    kubernetes.io/cluster-service: 'true'
    version: v1.1
  name: honeycomb-agent
  namespace: default
spec:
  selector:
    matchLabels:
      app: honeycomb-agent
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  template:
    metadata:
      labels:
        app: honeycomb-agent
        kubernetes.io/cluster-service: 'true'
        version: v1.1
    spec:
      tolerations:
        - operator: Exists
          effect: NoSchedule
      containers:
      - env:
        - name: HONEYCOMB_WRITEKEY
          valueFrom:
            secretKeyRef:
              key: key
              name: honeycomb-writekey
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        image: honeycombio/honeycomb-kubernetes-agent:head
        imagePullPolicy: IfNotPresent
        name: honeycomb-agent
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 200Mi
        volumeMounts:
        - mountPath: "/etc/honeycomb"
          name: config
          readOnly: false
        - mountPath: "/var/log"
          name: varlog
          readOnly: false
        - mountPath: "/var/lib/docker/containers"
          name: varlibdockercontainers
          readOnly: true
      serviceAccountName: honeycomb-serviceaccount
      terminationGracePeriodSeconds: 30
      volumes:
      - configMap:
          items:
          - key: config.yaml
            path: config.yaml
          name: honeycomb-agent-config
        name: config
      - hostPath:
          path: "/var/log"
        name: varlog
      - hostPath:
          path: "/var/lib/docker/containers"
        name: varlibdockercontainers
---
apiVersion: v1
kind: Secret
metadata:
  name: honeycomb-writekey
type: Opaque
data:
  key: Zm9vCg==

